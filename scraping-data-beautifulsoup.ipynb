{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Data with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "BASE_URL = 'http://en.wikipedia.org'\n",
    "#Wikipedia will reject requests unless we add\n",
    "# a user-agent attribute to our http header\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "def get_Nobel_soup():\n",
    "    '''Return a parsed tag tree of our Nobel prize page'''\n",
    "    response = requests.get(\n",
    "        BASE_URL + '/wiki/List_of_Nobel_Laureates', headers=HEADERS)\n",
    "    #return the response parsed by BeautifulSoup\n",
    "    return BeautifulSoup(response.content, 'lxml') #lxml is one of the parser options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'href': '/wiki/List_of_Nobel_laureates_in_Physics', 'name': u'Physics'}, {'href': '/wiki/List_of_Nobel_laureates_in_Chemistry', 'name': u'Chemistry'}, {'href': '/wiki/List_of_Nobel_laureates_in_Physiology_or_Medicine', 'name': u'Physiology\\nor Medicine'}, {'href': '/wiki/List_of_Nobel_laureates_in_Literature', 'name': u'Literature'}, {'href': '/wiki/List_of_Nobel_Peace_Prize_laureates', 'name': u'Peace'}, {'href': '/wiki/List_of_Nobel_laureates_in_Economics', 'name': u'Economics'}]\n"
     ]
    }
   ],
   "source": [
    "soup = get_Nobel_soup()\n",
    "soup.find('table', {'class': 'wikitable sortable'})\n",
    "# this works, but fine is not very robust.  If we change the order\n",
    "# of the two classes we specified, it won't work if it doesn't match\n",
    "# the order that the two classes were defined in in the HTML\n",
    "soup.find('table', {'class': 'sortable wikitable'})\n",
    "\n",
    "# So instead of using BeautifulSoup's selectors (which are fragile)\n",
    "# we recommend using lxml's methods instead:\n",
    "soup.select('table.sortable.wikitable') #lxml uses CSS style selectors ('.' is class, '#' is id, etc.)\n",
    "# This works no matter the order of the classes and returns an *array* of all the matches\n",
    "\n",
    "table = soup.select_one('table.sortable.wikitable') #selects just the first one\n",
    "#print(table)\n",
    "table.select('th')\n",
    "# these lxml selectors also support regex and other approaches.\n",
    "\n",
    "def get_column_titles(table):\n",
    "    '''Get the Nobel categories from the table header'''\n",
    "    cols = []\n",
    "    for th in table.select_one('tr').select('th')[1:]: #loop through table head, ignoring leftmost year column\n",
    "        link = th.select_one('a')\n",
    "        if link:\n",
    "            cols.append({'name': link.text,\n",
    "                        'href': link.attrs['href']})\n",
    "        else:\n",
    "            cols.append({'name':th.text, 'href': None})\n",
    "    return cols\n",
    "            \n",
    "print( get_column_titles(table) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'category': u'Physics', 'link': '/wiki/Wilhelm_R%C3%B6ntgen', 'name': u'Wilhelm R\\xf6ntgen', 'year': 1901}, {'category': u'Chemistry', 'link': '/wiki/Jacobus_Henricus_van_%27t_Hoff', 'name': u\"Jacobus Henricus van 't Hoff\", 'year': 1901}]\n"
     ]
    }
   ],
   "source": [
    "def get_Nobel_winners(table):\n",
    "    cols = get_column_titles(table)\n",
    "    winners = []\n",
    "    for row in table.select('tr')[1:-1]:\n",
    "        try:\n",
    "            year = int(row.select_one('td').text) #Gets first <td>\n",
    "        except ValueError:\n",
    "            year = None\n",
    "        for i, td in enumerate(row.select('td')[1:]):\n",
    "            for winner in td.select('a'):\n",
    "                href = winner.attrs['href']\n",
    "                if not href.startswith('#endnote'):\n",
    "                    winners.append({\n",
    "                        'year':year,\n",
    "                        'category':cols[i]['name'],\n",
    "                        'name':winner.text,\n",
    "                        'link':winner.attrs['href']\n",
    "                    })\n",
    "    return winners\n",
    "\n",
    "winners = get_Nobel_winners(table)\n",
    "print(winners)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching web pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can make large numbers of requests, it is best to cache results.  The python package 'requests-cache' makes this easy.  It has useful options like specifying the cache backend (memory or a DB) and setting an expiration time for the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests_cache\n",
    "\n",
    "requests_cache.install_cache('nobel_pages', backend='sqlite', expire_after=7200)\n",
    "#use requests as usual..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow link and scrape nationality from bio page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': u'\\xc9lie Ducommun'}, {'name': u'Charles Albert Gobat'}, {'name': u'Marie Curie'}, {'name': u'Niels Ryberg Finsen'}, {'name': u'Ivan Pavlov'}, {'name': u'Institut de Droit International'}, {'name': u'Philipp Lenard'}, {'name': u'Bertha von Suttner'}, {'name': u'Santiago Ram\\xf3n y Cajal'}, {'name': u'Theodore Roosevelt'}, {'name': u'Ernesto Teodoro Moneta'}, {'name': u'Louis Renault'}, {'name': u'Paul Ehrlich'}, {'name': u'Rudolf Christoph Eucken'}, {'name': u'Klas Pontus Arnoldson'}]\n"
     ]
    }
   ],
   "source": [
    "def get_winner_nationality(w):\n",
    "    '''scrape bio data from the winner's wikipedia page'''\n",
    "    response = requests.get('http://en.wikipedia.org' + w['link'], headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "    person_data = {'name': w['name']}\n",
    "    attr_rows = soup.select('table.infobox tr') #remember, this is CSS-style selectors\n",
    "    for tr in attr_rows:\n",
    "        try:\n",
    "            attribute = tr.select_one('th').text\n",
    "            if attribute == 'Nationality':\n",
    "                person_data[attribute] = tr.select_one('td').text\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    return person_data\n",
    "\n",
    "# test the get_winner_nationality\n",
    "wdata = []\n",
    "# test first 50 winners\n",
    "for w in winners[:50]:\n",
    "    wdata.append(get_winner_nationality(w))\n",
    "missing_nationality = []\n",
    "for w in wdata:\n",
    "    # if missing 'Nationality' add to list\n",
    "    if not w.get('Nationality'):\n",
    "        missing_nationality.append(w)\n",
    "print(missing_nationality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
